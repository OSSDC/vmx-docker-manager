#!/bin/sh
# VMX Model Manager
#
# Copyright vision.ai 2015

#always run in current directory
cd "`dirname "$0"`"

#Change the remote URL if you want to download models from another VMX endpoint
#REMOTE_URL="http://192.168.1.103:3000"
REMOTE_URL="https://models.vision.ai"

#Change the local URL if VMX is running on another port or using HTTPS
#LOCAL_URL="http://localhost:3000"
LOCAL_URL="http://localhost:3000"

#The directory where we make VMX model tarballs after downloading
DOWNLOAD_DIRECTORY=`pwd`'/incoming'

#The user/ip of the server we will try to upload to
UPLOAD_SSH="root@models.vision.ai"

#The URL to check if the models were imported or not
UPLOAD_URL="https://models.vision.ai"

# The directory on the upload server where models get imported
UPLOAD_DIR="/home/root/vmx-docker-manager/incoming"

print_header() {
   M="`basename "$0"`"
   echo "VMX Model Manager by vision.ai (version ""`git describe --tags --dirty 2>/dev/null || md5 -q "$M" 2> /dev/null || md5sum "$M" | awk '{print($1)}'`"")"
}

usage () {
  print_header

  echo "==============================================="
  echo ""
  echo "LOCAL_URL="$LOCAL_URL
  echo "DOWNLOAD_DIRECTORY=$DOWNLOAD_DIRECTORY"
  echo "REMOTE_URL="$REMOTE_URL
  echo "UPLOAD_SSH="$UPLOAD_SSH
  echo "UPLOAD_URL="$UPLOAD_URL
  echo "UPLOAD_DIR="$UPLOAD_DIR
  echo ""
  echo "Usage: models.sh COMMAND [OPTIONS]"
  echo 
  echo "Commands:"
  echo "    download [a] [b] [c]: Download models from remote server REMOTE_URL into incoming folder"
  echo "    import:               Import models from incoming folder into VMX model directory"
  echo "    upload model_name:    Upload models to a remote location via SSH"
  echo " "
  echo "Examples:"
  echo " - Download all publicly available models from REMOTE_URL"
  echo "    $  ./models download -all"
  echo " "
  echo " - Download face, dog, eyes from REMOTE_URL"
  echo "    $  ./models download face dog eyes"
  echo " "
  echo " - Import downloaded models into local VMX"
  echo "    $  ./models import"
  echo " "
  echo " - Upload a model called gesture-pack-12"
  echo "    $  ./models upload gesture-pack-12"
  echo " "
  echo " - Upload two models gesture-pack-12 and gesture-pack-14"
  echo "    $  ./models upload gesture-pack-12 gesture-pack-14"
  echo " "
  echo " - Upload all models"
  echo "    $  ./models upload -all"
  echo " "
  if [ -e ".git" ]; then
    echo " - Update the vmx-docker-manager"
    echo "    $  git pull"
    echo " "
  fi
  echo " - Update the vmx-model-manager"
  echo "    $  wget https://raw.githubusercontent.com/VISIONAI/vmx-docker-manager/master/models"
  exit 1
}



check_dependencies() {
    # Dependencies: jq, curl, gzip, tar
    if [ "`which jq`" = "" ]; then
        echo "Dependency jq is missing, exiting"
        exit 1
    fi

    if [ "`which curl`" = "" ]; then
        echo "Dependency curl is missing, exiting"
        exit 1
    fi

    if [ "`which gzip`" = "" ]; then
        echo "Dependency gzip is missing, exiting"
        exit 1
    fi

    if [ "`which tar`" = "" ]; then
        echo "Dependency tar is missing, exiting"
        exit 1
    fi
}

#Make sure that the remote URL is responding
check_remote_url() {
    if [ "`curl -s ${REMOTE_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing remote models at REMOTE_URL=${REMOTE_URL}"
        echo "Please change REMOTE_URL"
        exit 1
    fi
}

#Make sure that the local URL is responding
check_local_url() {
    if [ "`curl -s ${LOCAL_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing local models at LOCAL_URL=${LOCAL_URL}"
        echo "Please change LOCAL_URL"
        exit 1
    fi
}


#Make sure that the upload endpoint is responding
check_upload_url() {
    if [ "`curl -s ${UPLOAD_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing remote models at UPLOAD_URL=${UPLOAD_URL}"
        echo "Please change UPLOAD_URL"
        exit
    fi
}


#Make sure that the upload endpoint is SSH-able
check_upload_ssh() {
    HI=`ssh -o PreferredAuthentications=publickey $UPLOAD_SSH "echo hi" 2>/dev/null`
    if [ "$HI" = "" ]; then
        echo "Improper credentials for talking to ${UPLOAD_URL}"
        echo "Remember to log-in with: ssh-add && ssh -A this.box.ip"
        exit 1
    fi

}


# The function to download models
download() {

    check_remote_url
    check_local_url
    
    mkdir -p "$DOWNLOAD_DIRECTORY"

    LOCAL_UUIDS=`curl -s ${LOCAL_URL}/model | jq -r '.data[] .uuid'`

    if [ "$MODEL_NAME" = "-all" ]; then
        echo "This script will download all models from" $REMOTE_URL "which do not exist in" $LOCAL_URL "into $DOWNLOAD_DIRECTORY"
        REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] .uuid'`
    else
        REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] | select(.name=="'$MODEL_NAME'") .uuid'`
        
        #If we didn't find a model.name matching, then maybe the user specified a UUID instead?
        if [ -z "$REMOTE_UUIDS" ]; then
            REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] | select(.uuid=="'$MODEL_NAME'") .uuid'`
        fi
    fi

    if [ -z "$REMOTE_UUIDS" ]; then
        echo "----------"
        echo "No remote models on $REMOTE_URL matching" $MODEL_NAME
        return
    fi

    for UUID in $REMOTE_UUIDS; do
        FINAL_TARBALL=$DOWNLOAD_DIRECTORY/${UUID}.tar.gz
        echo "----------"
        if [ -e $FINAL_TARBALL ]; then
            echo $MODEL_NAME ${UUID}.tar.gz "already exists, skipping download"
        elif [ ! -n "`echo $LOCAL_UUIDS | grep $UUID`" ]; then
            echo $MODEL_NAME $UUID "not found in" $LOCAL_URL "so downloading"
            mkdir $DOWNLOAD_DIRECTORY/$UUID/ 2> /dev/null
            cd $DOWNLOAD_DIRECTORY/$UUID

            curl -# -C - -O $REMOTE_URL/models/$UUID/image.jpg \
                -O -C - $REMOTE_URL/models/$UUID/model.json \
                -O -C - $REMOTE_URL/models/$UUID/compiled.data \
                -O -C - $REMOTE_URL/models/$UUID/data_set.json \
                -O -C - $REMOTE_URL/models/$UUID/model.data
            cd - > /dev/null 2>&1

            #Now we make a tarball from the downloaded files
            echo "Making tarball" $FINAL_TARBALL
            cd $DOWNLOAD_DIRECTORY/
            tar cfz $UUID.tar.gz $UUID
            
            #And cleanup the directory
            rm -rf $UUID
            cd - > /dev/null 2>&1
        else
            echo $MODEL_NAME $UUID "already exists inside" $LOCAL_URL
        fi    
    done    
}

#Imports the tarballs into the local model store, works with native
#Mac OS X version and with the Dockerized version
import() {
    NFILES=(`ls $DOWNLOAD_DIRECTORY/*.gz 2>/dev/null | wc -l`)
    echo "Number of tarballs in" $DOWNLOAD_DIRECTORY "is" $NFILES
    if [ "$NFILES" = "0" ]; then
        echo "No models to import, exiting"
        exit
    #else
        #echo "Importing $NFILES models"
    fi
    
    cd $DOWNLOAD_DIRECTORY
    FILES=`find . -name "*.tar.gz"`
    cd - > /dev/null 2>&1

    # If non-empty, then LOCAL_URL is a Mac
    if [ `uname` = "Linux" ]; then
        IS_MAC=""
    else
        IS_MAC=`curl -s localhost:3000/check | jq -r ".version[0]" | grep Mac`
    fi


    if [ "$IS_MAC" ]; then    
        #The default location of models on a native Mac install (used for import)
        #MAC_MODELS="/Applications/VMX.app/Contents/MacOS/assets/models/"

        MAC_MODELS=`cat config/settings.yml | grep "wwwdir:" | head -1 | awk '{print($2)}' | sed 's/"//g'`/models
        echo "MAC_MODELS directory is" $MAC_MODELS
    fi
    
    for f in $FILES; do
        echo "Importing: " $f
        if [ "$IS_MAC" ]; then
            tar -C $MAC_MODELS -xf $DOWNLOAD_DIRECTORY/$f \
                && echo "Cleaning up" $DOWNLOAD_DIRECTORY/$f \
                && rm $DOWNLOAD_DIRECTORY/$f \
                || echo "Problem with" $DOWNLOAD_DIRECTORY/$f
        else
            docker run --rm --name vmx-export --volumes-from vmx-userdata:rw \
                -v $DOWNLOAD_DIRECTORY/$f:/incoming/$f ubuntu /bin/bash \
                -c "tar -C /vmx/models -xf /incoming/$f" \
                && echo "Cleaning up" $DOWNLOAD_DIRECTORY/$f \
                && rm $DOWNLOAD_DIRECTORY/$f \
                || echo "Problem with" $DOWNLOAD_DIRECTORY/$f
        fi
    done
}

#upload models
upload() {

    check_local_url
    check_upload_url
    check_upload_ssh
        
    #Get the UUID for the desired model
    UUID=`curl -s $LOCAL_URL/model | jq -r '.data[] | select(.name=="'$MODEL_NAME'") .uuid'`

    #If we didn't get a UUID from a model.name, then maybe a UUID was specified
    if [ ! -n "$UUID" ]; then
	UUID=`curl -s $LOCAL_URL/model | jq -r '.data[] | select(.uuid=="'$MODEL_NAME'") .uuid'`    
    fi

    if [ ! -n "$UUID" ]; then
        echo "Error: Cannot find model $MODEL_NAME in local models $LOCAL_URL"
        echo "Not copying"
	return
    fi
    
    #check if that UUID is present on the remote server
    IS_PRESENT=`curl -s $UPLOAD_URL/model | jq -r '.data[] | select(.uuid=="'$UUID'") .name'`
    
    if [ -n "$IS_PRESENT" ]; then
        echo "Warning: already found model" $MODEL_NAME "UUID" $UUID "on remote server" $UPLOAD_URL
        echo "Not copying"
        return
    fi
    
    echo UUID of object $MODEL_NAME is $UUID
    
    TMP_UPLOAD_DIR=/tmp/vmx_upload_temp/
    
    TARBALL=${TMP_UPLOAD_DIR}/$UUID.tar
    mkdir -p ${TMP_UPLOAD_DIR}/$UUID
    OLDCWD=`pwd`
    cd ${TMP_UPLOAD_DIR}/$UUID

    #use curl to pull down models    
    curl -# -C - -O $LOCAL_URL/models/$UUID/image.jpg \
        -O -C - $LOCAL_URL/models/$UUID/model.json \
        -O -C - $LOCAL_URL/models/$UUID/compiled.data \
        -O -C - $LOCAL_URL/models/$UUID/data_set.json \
        -O -C - $LOCAL_URL/models/$UUID/model.data
    cd ..

    echo "Creating tarball"
    tar cf $TARBALL $UUID
    cd ${OLDCWD} > /dev/null 2>&1
    gzip $TARBALL
    TARBALL=${TARBALL}.gz
    
    echo "Copying tarball"
    ssh $UPLOAD_SSH "mkdir -p $UPLOAD_DIR"
    scp $TARBALL $UPLOAD_SSH:$UPLOAD_DIR
    
    echo "Importing into remote container"
    ssh $UPLOAD_SSH "~/vmx-docker-manager/models import"
    
    echo "Clearing tarball on local"
    rm $TARBALL
    
    #cd - > /dev/null 2>&1
}

[ $# -lt 1 ] && {
  usage
}


print_header


check_dependencies

cmd=$1

case "$cmd" in
    download)
        [ $# -lt 2 ] && {
	    echo "Usage: $0 download model_name1 [model_name2] [model_name3]" >&2
	    VALID_NAMES=`curl -s ${REMOTE_URL}/model | jq -r '.data[] .name'`
	    echo "Valid names are:" $VALID_NAMES
	    exit
        }

        while [ "$#" -gt 0 ]; do
            MODEL_NAME=$2
            if [ ! -z "$MODEL_NAME" ]; then
                download
            fi
            shift
        done
        NUM_TARBALLS=(`ls $DOWNLOAD_DIRECTORY | wc -l`)
        if [ $NUM_TARBALLS -gt 0 ]; then
            echo "Found ${NUM_TARBALLS} tarballs, to import run: ./models import"
        #else
            #echo "Nothing to import inside $DOWNLOAD_DIRECTORY"
        fi
        exit 0
        ;;

    import)
        import
        exit 0
        ;;

    upload)
        [ $# -lt 2 ] && {
	    echo "Usage: $0 upload model_name1 [model_name2] [model_name3]" >&2
	    VALID_NAMES=`curl -s ${LOCAL_URL}/model | jq -r '.data[] .name'`
	    echo "Valid names are:" $VALID_NAMES
	    exit
        }
	
	#allow ./models upload -all
	[ $# -eq 2 ] && [ "$2" = "-all" ] && {
	    echo "About to upload all models"
	    VALID_NAMES=`curl -s ${LOCAL_URL}/model | jq -r '.data[] .name'`
	    $0 upload $VALID_NAMES
	    exit
	}

        while [ "$#" -gt 0 ]; do
            MODEL_NAME=$2
            if [ ! -z "$MODEL_NAME" ]; then
                upload
            fi
            shift
        done

        exit 0
        ;;

    *)
        usage
esac
