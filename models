#!/bin/sh
# VMX Model Manager
#
# download: Script to download all VMX models from a remote VMX server such as
# models.vision.ai into a local VMX server such as one running on
# localhost:3000. 
#
# import: Script to import all models (represented as tarballs) from the
# DOWNLOAD_DIRECTORY folder into the vmx model container. This script
# will process the tarballs one by one, deleting the tarball after a
# successful import.
#
# upload: Admin tool to upload local models from a VMX node into
# models.vision.ai. Requires administrator priviledges (SSH key) on
# models.vision.ai.
# 
# Copyright vision.ai 2015

#always run in current directory
cd `dirname $0`

#Change the remote URL if you want to download models from another VMX endpoint
#REMOTE_URL="http://192.168.1.103:3000"
REMOTE_URL="https://models.vision.ai"

#Change the local URL if VMX is running on another port or using HTTPS
#LOCAL_URL="http://localhost:3000"
LOCAL_URL="http://localhost:3000"

#The directory where we make VMX model tarballs after downloading
DOWNLOAD_DIRECTORY=`pwd`'/incoming'

#The user/ip of the server we will try to upload to
UPLOAD_SSH="root@test.vision.ai"

#The URL to check if the models were imported or not
UPLOAD_URL="https://test.vision.ai"

# The directory on the upload server where models get imported
UPLOAD_DIR="~/vmx-docker-manager/incoming"

#The default location of models on a native Mac install (used for import)
MAC_MODELS="/Applications/VMX.app/Contents/MacOS/assets/models/"

# If non-empty, then LOCAL_URL is a Mac
if [ `uname` = "Linux" ]; then
    IS_MAC=""
else
    IS_MAC=`curl -s localhost:3000/check | jq -r ".version[0]" | grep Mac`
fi

usage () {
  echo "VMX Model Manager by vision.ai"
  echo "Version: " `git describe --tags --dirty 2>/dev/null || echo no-git`
  echo "Requires docker >= 1.2; and permissions to run docker"
  echo "==============================================="
  echo "Usage: models.sh COMMAND [OPTIONS]"
  echo 
  echo "Commands:"
  echo "    download [a] [b] [c]: Download models from remote server models.vision.ai into incoming folder"
  echo "    import:   Import models from incoming folder into VMX container"
  echo "    upload model_name:   Upload models to a remote location via SSH"
  echo " "
  echo "Examples:"
  echo " - Download all publicly available models from models.vision.ai"
  echo "    $  ./models download -all"
  echo " "
  echo " - Download a,b,c from models.vision.ai"
  echo "    $  ./models download a b c"
  echo " "
  echo " - Import downloaded models into local VMX"
  echo "    $  ./models import"
  echo " "
  echo " - Upload a model called gesture-pack-12"
  echo "    $  ./models upload gesture-pack-12"
  echo " "
  echo " - Update the vmx-docker-manager"
  echo "    $  git pull"

  exit 1
}

check_dependencies() {
    # Dependencies: jq, curl, gzip, tar
    if [ "`which jq`" = "" ]; then
        echo "Dependency jq is missing, exiting"
        exit 1
    fi

    if [ "`which curl`" = "" ]; then
        echo "Dependency curl is missing, exiting"
        exit 1
    fi

    if [ "`which gzip`" = "" ]; then
        echo "Dependency gzip is missing, exiting"
        exit 1
    fi

    if [ "`which tar`" = "" ]; then
        echo "Dependency tar is missing, exiting"
        exit 1
    fi
}

#Make sure that the remote URL is responding
check_remote_url() {
    if [ "`curl -s ${REMOTE_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing remote models at REMOTE_URL=${REMOTE_URL}"
        echo "Please change REMOTE_URL"
        exit
    fi
}

#Make sure that the local URL is responding
check_local_url() {
    if [ "`curl -s ${LOCAL_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing local models at LOCAL_URL=${LOCAL_URL}"
        echo "Please change LOCAL_URL"
        exit
    fi
}


#Make sure that the upload endpoint is responding
check_upload_url() {
    if [ "`curl -s ${UPLOAD_URL}/model | jq -r '.data' 2> /dev/null`" = "" ]; then
        echo "Problem listing remote models at UPLOAD_URL=${UPLOAD_URL}"
        echo "Please change UPLOAD_URL"
        exit
    fi
}


#Make sure that the upload endpoint is SSH-able
check_upload_ssh() {
    HI=`ssh -o PreferredAuthentications=publickey $UPLOAD_SSH "echo hi" 2>/dev/null`
    if [ "$HI" = "" ]; then
        echo "Improper credentials for talking to ${UPLOAD_URL}"
        echo "Remember to log-in with: ssh-add && ssh -A this.box.ip"
        exit 1
    fi

}


# The function to download models
download() {

    check_remote_url
    check_local_url
    
    if [ ! -e $DOWNLOAD_DIRECTORY ]; then
        echo "Directory" $DOWNLOAD_DIRECTORY "does not exist"
        echo "Make the directory or change DOWNLOAD_DIRECTORY"
        exit
    fi

    LOCAL_UUIDS=`curl -s ${LOCAL_URL}/model | jq -r '.data[] .uuid'`

    if [ "$MODEL_NAME" = "-all" ]; then
        echo "This script will download all models from" $REMOTE_URL "which do not exist in" $LOCAL_URL "into" $DOWNLOAD_DIRECTORY
        REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] .uuid'`
    else
        REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] | select(.name=="'$MODEL_NAME'") .uuid'`
        
        #If we didn't find a model.name matching, then maybe the user specified a UUID instead?
        if [ -z "$REMOTE_UUIDS" ]; then
            REMOTE_UUIDS=`curl -s ${REMOTE_URL}/model | jq -r '.data[] | select(.uuid=="'$MODEL_NAME'") .uuid'`
        fi
    fi

    if [ -z "$REMOTE_UUIDS" ]; then
        echo "----------"
        echo "No remote uuids matching" $MODEL_NAME
        return
    fi

    for UUID in $REMOTE_UUIDS; do
        FINAL_TARBALL=$DOWNLOAD_DIRECTORY/${UUID}.tar.gz
        echo "----------"
        if [ -e $FINAL_TARBALL ]; then
            echo $FINAL_TARBALL "already exists, skipping download"
        elif [ ! -n "`echo $LOCAL_UUIDS | grep $UUID`" ]; then
            echo $UUID "not found in" $LOCAL_URL "so downloading"
            mkdir $DOWNLOAD_DIRECTORY/$UUID/ 2> /dev/null
            cd $DOWNLOAD_DIRECTORY/$UUID

            curl -# -C - -O $REMOTE_URL/models/$UUID/image.jpg \
                -O -C - $REMOTE_URL/models/$UUID/model.json \
                -O -C - $REMOTE_URL/models/$UUID/compiled.data \
                -O -C - $REMOTE_URL/models/$UUID/data_set.json \
                -O -C - $REMOTE_URL/models/$UUID/model.data
            cd - > /dev/null 2>&1

            #Now we make a tarball from the downloaded files
            echo "Making tarball" $FINAL_TARBALL
            cd $DOWNLOAD_DIRECTORY/
            tar cfz $UUID.tar.gz $UUID
            
            #And cleanup the directory
            rm -rf $UUID
            cd - > /dev/null 2>&1
        else
            echo $UUID "already exists inside" $LOCAL_URL
        fi    
    done    
}

#Imports the tarballs into the local model store, works with native
#Mac OS X version and with the Dockerized version
import() {
    NFILES=`ls $DOWNLOAD_DIRECTORY/*.gz 2>/dev/null | wc -l`
    echo "Number of models in" $DOWNLOAD_DIRECTORY "is" $NFILES
    if [ "$NFILES" = "0" ]; then
        echo "No models to import, exiting"
        exit
    else
        echo "Importing $NFILES models"
    fi
    
    cd $DOWNLOAD_DIRECTORY
    FILES=`find . -name "*.tar.gz"`
    cd - > /dev/null 2>&1
    for f in $FILES; do
        echo "Importing: " $f
        if [ "$IS_MAC" ]; then
            tar -C $MAC_MODELS -xf $DOWNLOAD_DIRECTORY/$f \
                && echo "Cleaning up" $DOWNLOAD_DIRECTORY/$f \
                && rm $DOWNLOAD_DIRECTORY/$f \
                || echo "Problem with" $DOWNLOAD_DIRECTORY/$f
        else
            docker run --rm --name vmx-export --volumes-from vmx-userdata:rw \
                -v $DOWNLOAD_DIRECTORY/$f:/incoming/$f ubuntu /bin/bash \
                -c "tar -C /vmx/models -xf /incoming/$f" \
                && echo "Cleaning up" $DOWNLOAD_DIRECTORY/$f \
                && rm $DOWNLOAD_DIRECTORY/$f \
                || echo "Problem with" $DOWNLOAD_DIRECTORY/$f
        fi
    done
}

upload() {

    check_upload_url
    check_local_url    
    
    #Make sure we have two command line arguments
    if [ "$MODEL_NAME" = "" ]; then
        echo "Usage: $0 upload model_name" >&2
        
        VALID_NAMES=`curl -s $LOCAL_URL/model | jq -r '.data[] .name'`
        echo "Valid names are:" $VALID_NAMES
        exit
    fi
    
    check_upload_ssh
    
    #Get the UUID for the desired model
    UUID=`curl -s $LOCAL_URL/model | jq -r '.data[] | select(.name=="'$MODEL_NAME'") .uuid'`
    
    if [ ! -n "$UUID" ]; then
        echo "Error: Cannot find model" $MODEL_NAME "in local models" $LOCAL_URL
        echo "Not copying"
        exit 1
    fi
    
    #check if that UUID is present on the remote server
    IS_PRESENT=`curl -s $UPLOAD_URL/model | jq -r '.data[] | select(.uuid=="'$UUID'") .name'`
    
    if [ -n "$IS_PRESENT" ]; then
        echo "Warning: already found model" $MODEL_NAME "UUID" $UUID "on remote server" $UPLOAD_URL
        echo "Not copying"
        exit
    fi
    
    echo UUID of object $MODEL_NAME is $UUID
    
    TMPDIR=/tmp/vmx_upload_temp/
    
    TARBALL=${TMPDIR}/$UUID.tar
    mkdir -p $TMPDIR/$UUID
    OLDCWD=`pwd`
    cd $TMPDIR/$UUID

    #use curl to pull down models    
    curl -# -C - -O $LOCAL_URL/models/$UUID/image.jpg \
        -O -C - $LOCAL_URL/models/$UUID/model.json \
        -O -C - $LOCAL_URL/models/$UUID/compiled.data \
        -O -C - $LOCAL_URL/models/$UUID/data_set.json \
        -O -C - $LOCAL_URL/models/$UUID/model.data
    cd ..

    echo "Creating tarball"
    tar cf $TARBALL $UUID
    cd ${OLDCWD} > /dev/null 2>&1
    gzip $TARBALL
    TARBALL=${TARBALL}.gz
    
    echo "Copying tarball"
    ssh $UPLOAD_SSH "mkdir -p $UPLOAD_DIR"
    scp $TARBALL $UPLOAD_SSH:$UPLOAD_DIR
    
    echo "Importing into remote container"
    ssh $UPLOAD_SSH "~/vmx-docker-manager/models import"
    
    echo "Clearing tarball on local"
    rm $TARBALL
    
    #cd - > /dev/null 2>&1
}

[ $# -lt 1 ] && {
  usage
}

#echo "Welcome to the vision.ai model manager"
check_dependencies

cmd=$1

case "$cmd" in
    download)
        [ $# -lt 2 ] && {
	    echo "Usage: $0 download model_name1 [model_name2] [model_name3]" >&2
	    VALID_NAMES=`curl -s ${REMOTE_URL}/model | jq -r '.data[] .name'`
	    echo "Valid names are:" $VALID_NAMES
	    exit
        }

        while [ "$#" -gt 0 ]; do
            MODEL_NAME=$2
            if [ ! -z "$MODEL_NAME" ]; then
                download
            fi
            shift
        done
        echo "Done downloading, to import run: ./models import"
        exit 0
        ;;

    import)
        import
        exit 0
        ;;

    upload)
        while [ "$#" -gt 0 ]; do
            MODEL_NAME=$2
            if [ ! -z "$MODEL_NAME" ]; then
                upload
            fi
            shift
        done

        exit 0
        ;;

    *)
        usage
esac
